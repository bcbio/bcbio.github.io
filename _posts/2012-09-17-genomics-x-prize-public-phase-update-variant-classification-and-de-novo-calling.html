---
layout: post
title: ! 'Genomics X Prize public phase update: variant classification and de novo
  calling'
date: 2012-09-17 08:41:00.000000000 -04:00
categories:
- xprize
tags:
- small-variants
- germline
- validation
- visualization
- xprize
status: publish
type: post
published: true
meta:
  _edit_last: '6099765'
  _oembed_08ff66128f0863e9fdd81527be7a7e82: ! '{{unknown}}'
  _oembed_d477247f39d7f712b29248c39d8a4cb1: ! '{{unknown}}'
  _oembed_ba254cc24311d3b64cb0ebd2ba2f25f3: ! '{{unknown}}'
author: brad_chapman
excerpt: !ruby/object:Hpricot::Doc
---
<div id="outline-container-1" class="outline-2">
<h2 id="sec-1">Background</h2>
<div class="outline-text-2" id="text-1">
<p> Last month <a href="#bc-public-phase">I described our work</a> at <a href="http://compbio.sph.harvard.edu/chb/">HSPH</a> and <a href="http://www.edgebio.com/">EdgeBio</a> preparing reference genomes for the <a href="http://genomics.xprize.org/">Archon Genomics X Prize</a> public phase, detailing methods used in the first version of our NA19239 variant calls. We've been steadily improving the calling approaches, and released version 0.2 on the <a href="https://validationprotocol.org/">X Prize validation website</a> and <a href="http://www.genomespace.org/">GenomeSpace</a>. Here I'll describe the improvements we've made over the last month, focusing on two specific areas: </p>
<ul>
<li><i>De novo</i> calling: Zam Iqbal suggested using <a href="http://cortexassembler.sourceforge.net/index_cortex_var.html">his cortex_var <i>de novo</i> variant caller</a>   in addition to the current GATK, FreeBayes and samtools callers.   With his help, we've included these calls in this release, and   provide comparisons between <i>de novo</i> and alignment based methods.  </li>
<li>Improved variant classification: Consolidating variant calls from   multiple callers involves making tough choices about when to include   or exclude variants. I'll describe the details of selecting metrics   for use in SVM classification and filtering of variants. </li>
</ul>
<p> Our goal is to iteratively improve our calling and variant preparation to create the best possible set of reference calls. I'd be happy to talk more with anyone working on similar problems or with insight into useful ways to improve our current callsets. We have a <a href="http://agxpprotocol.xprize.org/agxp">Get Satisfaction site</a> for discussion and feedback, and have offered a <a href="http://agxpprotocol.xprize.org/agxp/topics/_2_500_bioinformatics_challenge">$2500 prize for helpful comments</a>. </p>
<p> As a reminder, all of the code and data used here is freely available: </p>
<ul>
<li>The <a href="#bcbio-variation">variant analysis infrastructure</a>, built on top of <a href="http://www.broadinstitute.org/gatk/">GATK,</a> automates   genome preparation, normalization and comparison. It provides a full   pipeline, driven by simple configuration files, for consolidating   multiple variant calls.  </li>
<li>The combined variant calls, including training data and potential true   and false positives, are available from <a href="http://www.genomespace.org/">GenomeSpace</a>:   <code>Public/chapmanb/xprize/NA19239-v0_2</code>.  </li>
<li>The individual variant calls for each technology and calling method are   also available from <a href="http://www.genomespace.org/">GenomeSpace</a>: <code>Public/EdgeBio/PublicData/Release1</code>. </li>
</ul></div>
</p></div>
<div id="outline-container-2" class="outline-2">
<h2 id="sec-2"><i>de novo</i> variant calling with cortex_var</h2>
<div class="outline-text-2" id="text-2">
<p> <i>de novo</i> variant calling performs reference-free assembly of either local or global genome regions, then subsequently uses these assemblies to call variants relative to a known reference. The advantage is that assemblies can avoid errors associated with mapping to the reference, helping resolve large variations as well as small variations near problem alignments or low complexity regions. </p>
<p> Hybrid approaches that use localized <i>de novo</i> assembly in variant regions help mitigate the extensive computational requirements associated with whole-genome assembly. <a href="http://www.completegenomics.com/FAQs/Assembly-Mapping-and-Variant-Calling/">Complete Genomics variant calling</a> and <a href="http://www.broadinstitute.org/gatk/gatkdocs/org_broadinstitute_sting_gatk_walkers_haplotypecaller_HaplotypeCaller.html">GATK 2.0's Haplotype Caller</a> both provide pipelines for hybrid <i>de novo</i> assembly in variant detection. The <a href="https://github.com/lh3/fermi">fermi</a> and <a href="https://github.com/jts/sga">SGA</a> assemblers are also used in variant calling, although the paths from assembly to variants are not as automated. </p>
<p> Thanks to Zam's generous assistance, we used <a href="http://cortexassembler.sourceforge.net/index_cortex_var.html">cortex_var</a> for localized <i>de novo</i> assembly and variant calling within individual fosmid boundaries. As a result, <a href="http://cloudbiolinux.org/">CloudBioLinux</a> now contains <a href="https://github.com/chapmanb/cloudbiolinux/blob/master/cloudbio/custom/bio_nextgen.py#L576">automated build instructions for cortex_var</a> , handling binary builds for multiple k-mer and color combinations. An <a href="https://github.com/chapmanb/bcbb/blob/master/nextgen/bcbio/variation/cortex.py">automated cortex_var pipeline</a>, part of the <a href="https://github.com/chapmanb/bcbb/tree/master/nextgen">bcbio-nextgen</a> toolkit, runs the processing workflow: </p>
<ul>
<li>Start with reads aligned to fosmid regions using novoalign.  </li>
<li>For each fosmid region, extract all mapped reads along with a local   reference genome for variant calling.  </li>
<li><i>de novo</i> assemble all reads in the fosmid region and call variants   against the local reference genome using cortex_var's Bubble Caller.  </li>
<li>Remap regional variant coordinates back to the full genome.  </li>
<li>Combine all regional calls into the final set of cortex_var calls. </li>
</ul>
<p> Directly comparing GATK and cortex_var calls shows similar levels of concordance and discordance as the GATK/samtools comparison from the last post: </p>
<table border="1" cellspacing="0" cellpadding="6" rules="all" style="width:350px;">
<caption></caption>
<col class="left" />
<col class="right" />
<tbody>
<tr>
<td class="left">concordant: total</td>
<td class="right">153787</td>
</tr>
<tr>
<td class="left">concordant: SNPs</td>
<td class="right">130913</td>
</tr>
<tr>
<td class="left">concordant: indels</td>
<td class="right">22874</td>
</tr>
<tr>
<td class="left">GATK discordant: total</td>
<td class="right">20495</td>
</tr>
<tr>
<td class="left">GATK discordant: SNPs</td>
<td class="right">6522</td>
</tr>
<tr>
<td class="left">GATK discordant: indels</td>
<td class="right">13973</td>
</tr>
<tr>
<td class="left">cortex_var discordant: total</td>
<td class="right">26790</td>
</tr>
<tr>
<td class="left">cortex_var discordant: SNPs</td>
<td class="right">21342</td>
</tr>
<tr>
<td class="left">cortex_var discordant: indels</td>
<td class="right">5448</td>
</tr>
</tbody>
</table>
<p> 11% of the GATK calls and 14% of the cortex_var calls are discordant. The one area where cortex_var does especially well is on indels: 19% of the cortex_var indels do not agree with GATK, in comparison with 37% of the GATK calls and 25% of the samtools calls. The current downside to this is SNP calling, where cortex_var has 3 times more discordant calls than GATK. </p>
</p></div>
</p></div>
<div id="outline-container-3" class="outline-2">
<h2 id="sec-3">Selection of classification metrics</h2>
<div class="outline-text-2" id="text-3">
<p> Overlapping variant calls from different calling methods (GATK, FreeBayes, samtools and cortex_var) and sequencing technologies (Illumina, SOLiD and IonTorrent) produces 170,286 potential calls in the fosmid regions. 58% (99,227) of these are present in all callers and technologies, so we need to do better than the intersection in creating a consolidated callset. </p>
<p> As detailed in the previous post, we filter the full set in two ways. The first is to keep trusted variants based on their presence in a defined number of technologies or callers. We currently have an inclusive set of criteria: keep variants present in either 4 out of the 7 callsets, 2 distinct technologies, or 3 distinct callers. This creates a trusted set containing 95% (162,202) of the variants. Longer term the goal is to reduce the trusted count and rely on automated filtering approaches based on input metrics. </p>
<p> This second automated filtering step uses a support vector machine (SVM) to evaluate the remaining variants. We train the SVM on potential true positives from variants that overlap in all callers and technologies, and potential false positives found uniquely in one single caller. The challenge is to find useful metrics associated with these training variants that will help provide discrimination. </p>
<p> In version 0.1 we filtered with a vanilla set of metrics: depth and variant quality score. To identify additional metrics, we used a great variant visualization tool developed by <a href="http://keminglabs.com/">Keming Labs</a> alongside <a href="http://compbio.sph.harvard.edu/chb/">HSPH</a> and <a href="http://www.edgebio.com/">EdgeBio</a>. I'll write up more details about the tool once we have a demonstration website but the code is already <a href="https://github.com/lynaghk/vcf">available on GitHub</a>. </p>
<p> To remove variants preferentially associated with poorly mapping or misaligned reads, we identified two useful metrics. <code>ReadPosEndDist</code>, written as a <a href="https://github.com/chapmanb/bcbio.variation/blob/master/src/java/bcbio/variation/annotate/ReadPosEndDist.java">GATK annotation</a> by <a href="http://www.nist.gov/mml/biochemical/biomolecular/jzook_bio.cfm">Justin Zook at NIST</a>, identifies variants primarily supported by calls at the ends of reads. Based on visual examination, these associate with difficult to map regions, as identified by <a href="http://sourceforge.net/apps/mediawiki/gma-bio/index.php?title=Genomic_Dark_Matter:_The_limitations_of_short_read_mapping">Genome Mappability Scores</a>: </p>
<p>    [youtube=http://www.youtube.com/watch?v=mPvrxYPfm2I]
<p> Secondly, we identified problematic allele balances that differ from the expected ratios. For haploid fosmid calls, we expect 100% of reads to support variants and 0% to support reference calls (in diploid calls, you also need to handle heterozygotes with 50% expected allele balance). In practice, the distribution of reads can differ due to sequencer and alignment errors. We use a metric that measures deviation from the expected allele balance and associates closely with variant likelihoods: </p>
<p>   [youtube=http://www.youtube.com/watch?v=iTqmjSCCe4M]   </p></div>
</p></div>
<div id="outline-container-4" class="outline-2">
<h2 id="sec-4">Improved consolidated calls</h2>
<div class="outline-text-2" id="text-4">
<p> To assess the influence of adding <i>de novo</i> calls and additional filtering metrics on the resulting call set, we compare against whole genome Illumina and Complete Genomics calls for NA19239. Previously we'd noticed two major issues during this comparison: a high percentage of discordant indel calls and a technology bias signaled by better concordance with Illumina than Complete. </p>
<p> The comparison between fosmid and Illumina data shows a substantial improvement in the indel bias. Previously 46% of the total indel calls were discordant, indicative of a potential false positive problem. With <i>de novo</i> calls and improved filtering, we've lowered this to only 10% of the total calls. </p>
<table border="1" cellspacing="0" cellpadding="6" rules="all" style="width:350px;">
<caption></caption>
<col class="left" />
<col class="right" />
<tbody>
<tr>
<td class="left">concordant: total</td>
<td class="right">147684</td>
</tr>
<tr>
<td class="left">concordant: SNPs</td>
<td class="right">133861</td>
</tr>
<tr>
<td class="left">concordant: indels</td>
<td class="right">13823</td>
</tr>
<tr>
<td class="left">fosmid discordant: total</td>
<td class="right">7519</td>
</tr>
<tr>
<td class="left">fosmid discordant: SNPs</td>
<td class="right">5856</td>
</tr>
<tr>
<td class="left">fosmid discordant: indels</td>
<td class="right">1663</td>
</tr>
<tr>
<td class="left">Illumina discordant: total</td>
<td class="right">5640</td>
</tr>
<tr>
<td class="left">Illumina discordant: SNPs</td>
<td class="right">1843</td>
</tr>
<tr>
<td class="left">Illumina discordant: indels</td>
<td class="right">3797</td>
</tr>
</tbody>
</table>
<p> This improvement comes with a decrease in the total number of concordant indel calls, since we moved from 17,816 calls to 13,823. However a large number of these seemed to be Illumina specific since 60% of the previous calls were discordant when compared with Complete Genomics. The new callset reduces this discrepancy and only 22% of the indels are now discordant: </p>
<table border="1" cellspacing="0" cellpadding="6" rules="all" style="width:350px;">
<caption></caption>
<col class="left" />
<col class="right" />
<tbody>
<tr>
<td class="left">concordant: total</td>
<td class="right">139155</td>
</tr>
<tr>
<td class="left">concordant: SNPs</td>
<td class="right">127243</td>
</tr>
<tr>
<td class="left">concordant: indels</td>
<td class="right">11912</td>
</tr>
<tr>
<td class="left">fosmid discordant: total</td>
<td class="right">15484</td>
</tr>
<tr>
<td class="left">fosmid discordant: SNPs</td>
<td class="right">12028</td>
</tr>
<tr>
<td class="left">fosmid discordant: indels</td>
<td class="right">3456</td>
</tr>
<tr>
<td class="left">Complete Genomics discordant: total</td>
<td class="right">7311</td>
</tr>
<tr>
<td class="left">Complete Genomics discordant: SNPs</td>
<td class="right">4972</td>
</tr>
<tr>
<td class="left">Complete Genomics discordant: indels</td>
<td class="right">2273</td>
</tr>
</tbody>
</table>
<p> These comparisons provide some nice confirmation that we're moving in the right direction on filtering. As before, we extract potential false positives and false negatives to continue to refine the calls: potential false positives are those called in the fosmid dataset and in neither of the Illumina or Complete Genomics sets. Potential false negatives are calls that both Illumina and Complete agree on that the fosmid calls lack. </p>
<p> In the new callsets, there are 5,499 (3.5%) potential false positives and 1,422 (0.9%) potential false negatives. We've reduced potential false positives in the previous set from 10% with a slight increase in false negatives. These subsets are available along with the full callset on GenomeSpace. We're also working hard on an NA12878 callset with equivalent approaches and will make that available soon for community feedback. </p>
<p> I hope this discussion, open source code, and dataset release is useful to everyone working on problems of improving variant calling accuracy and filtering. I welcome feedback on calling, consolidation methods, interesting metrics to explore, machine learning or any of the other topics discussed here. </p>
</p></div>
</p></div>
