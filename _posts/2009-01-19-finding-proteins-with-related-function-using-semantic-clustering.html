---
layout: post
title: Finding proteins with related function using semantic clustering
date: 2009-01-19 12:34:57.000000000 -05:00
categories:
- semanticweb
tags:
- how-to
status: publish
type: post
published: true
meta: {}
author: brad_chapman
excerpt: !ruby/object:Hpricot::Doc
---
<p>
An immediate goal when investigating a protein of interest is to identify related proteins. There are several ways you can go about this:</p>
<ul>
<li>Search for proteins by sequence similarity, using <a href="http://blast.ncbi.nlm.nih.gov/Blast.cgi">BLAST</a> or other tools.</li>
<li>Search for proteins with similar characteristics, using features like <a href="http://www.ebi.ac.uk/interpro/">InterPro</a> domains.</li>
<li>Search for proteins determined to have similar functionality, using the literature.</li>
</ul>
<p>
Here we will automate the literature-functionality approach using <a href="http://www.zemanta.com/">Zemanta</a>. Previously, we talked about how well Zemanta <a href="http://bcb.io/2009/01/04/extracting-keywords-from-biological-text-using-zemanta/">extracted biological information from gene descriptions</a>. This can be used to classify <a href="http://www.uniprot.org/">UniProt</a> descriptions and find proteins with similar functionality to a target of interest.</p>
<p>
In this example, we will look for proteins similar to a <a href="http://www.uniprot.org/uniprot/P30658">Polycomb chromatin remodeling protein</a> in Mouse. As our base, we build a query of all mouse proteins in UniProt classified as repressors: <code>organism:"Mus musculus [10090]" AND keyword:"Repressor [678]"</code>. This provides 350 records, which can be downloaded using the UniProt web interface as a tab delimited file.</p>
<p>
Next, Zemanta is used to extract keywords linked to either Wikipedia or <a href="http://www.freebase.com/">Freebase</a>. Starting with <a href="http://bcb.io/2009/01/10/extracting-protein-characteristics-for-an-interpro-domain/">our UniProt XML retriever</a>, we get the functional descriptions:</p>
<p>[sourcecode language="python"]<br />
def get_description_terms(retriever, cur_id, api_key):<br />
    metadata = retriever.get_xml_metadata(cur_id)<br />
    if metadata.has_key("function_descr"):<br />
        keywords = zemanta_link_kws(metadata["function_descr"], api_key)<br />
        if len(keywords) > 0:<br />
            return keywords<br />
    return []<br />
[/sourcecode]</p>
<p>
These are fed into Zemanta, extracting the keywords:</p>
<p>[sourcecode language="python"]<br />
def zemanta_link_kws(search_text, api_key):<br />
    gateway = 'http://api.zemanta.com/services/rest/0.0/'<br />
    args = {'method': 'zemanta.suggest',<br />
            'api_key': api_key,<br />
            'text': search_text,<br />
            'return_categories': 'dmoz',<br />
            'return_images': 0,<br />
            'return_rdf_links' : 1,<br />
            'format': 'json'}<br />
    args_enc = urllib.urlencode(args)<br />
    raw_output = urllib2.urlopen(gateway, args_enc).read()<br />
    output = simplejson.loads(raw_output)<br />
    link_kws = []<br />
    for link in output['markup']['links']:<br />
        for target in link['target']:<br />
            if target['type'] in ['wikipedia', 'rdf']:<br />
                link_kws.append(target['title'])<br />
    return list(set(link_kws))<br />
[/sourcecode]</p>
<p>
With a list of UniProt IDs and keywords organized into a dictionary we then build a binary matrix of terms for clustering. This approach is described in the excellent book <a href="http://oreilly.com/catalog/9780596529321/">Programming Collective Intelligence</a>. The resulting matrix has UniProt IDs as rows and keyword terms as columns. Each value will be 1 if the term is contained in the Zemanta extracted keywords for that UniProt ID, or 0 otherwise:</p>
<p>[sourcecode language="python"]<br />
def organize_term_array(cur_db):<br />
    all_terms = reduce(operator.add, cur_db.values())<br />
    term_counts = collections.defaultdict(lambda: 0)<br />
    for term in all_terms:<br />
        term_counts[term] += 1<br />
    all_terms = list(set(all_terms))<br />
    term_matrix = []<br />
    all_ids = []<br />
    for uniprot_id, cur_terms in cur_db.items():<br />
        cur_row = [(1 if t in cur_terms else 0) for t in all_terms]<br />
        term_matrix.append(cur_row)<br />
        all_ids.append(uniprot_id)<br />
    return numpy.array(term_matrix), all_ids<br />
[/sourcecode]</p>
<p>
Finally, this matrix is fed into the <a href="http://biopython.org/DIST/docs/cluster/cluster.pdf">PyCluster</a> module in <a href="http://www.biopython.org/wiki/Biopython">Biopython</a> for <a href="http://en.wikipedia.org/wiki/K-means_algorithm">k-means clustering</a>. The clusters are examined and information on the other IDs clustered with our target organism are printed:</p>
<p>[sourcecode language="python"]<br />
cluster_ids, error, nfound = Cluster.kcluster(term_matrix,<br />
        nclusters=10, npass=20, method='a', dist='e')<br />
cluster_dict = collections.defaultdict(lambda: [])<br />
for i, cluster_id in enumerate(cluster_ids):<br />
    cluster_dict[cluster_id].append(uniprot_ids[i])<br />
for cluster_group in cluster_dict.values():<br />
    if target_id in cluster_group:<br />
        for item in cluster_group:<br />
            print item, cur_db[item]<br />
[/sourcecode]</p>
<p>
The <a href="http://github.com/chapmanb/bcbb/blob/master/rest_apis/uniprot_query_cluster.py">full script</a> shows all of these parts tied together. For our example, Zemanta pulls out the following keyword list: <code>['Polycomb-group proteins', 'Homeotic gene', 'Histone', 'Lys (department)', 'Chromatin', 'Histone H2A']</code> and clustering identifies 19 similar proteins. This could be presented through a web interface into which a scientist enters a protein of interest and gets back the resulting list for manual inspection.</p>
<p>
Conceptually, this automated approach is similar to an expert searching through the literature. Here, we are virtually clicking through Wikipedia links and noting similarities. By being able to leverage general purpose tools like Zemanta, we avoid having to build a science specific tool for this purpose. This is an additional argument for adoption of general tools like Wikipedia for <a href="http://mndoci.com/blog/2009/01/18/rethinking-wikipedia/">scientific annotation</a>.</p>
