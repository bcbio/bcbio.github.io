---
layout: post
title: ! 'Whole genome trio variant calling evaluation: low complexity regions, GATK
  VQSR and high depth filters'
date: 2014-05-12 06:03:22.000000000 -04:00
categories:
- variation
tags:
- small-variants
- validation
status: publish
type: post
published: true
meta:
  _edit_last: '6099765'
  _publicize_pending: '1'
author: brad_chapman
excerpt: !ruby/object:Hpricot::Doc
---
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Whole genome trio validation</h2>
<div class="outline-text-2" id="text-1">
<p> I've written previously about the approaches we use to validate the <a href="https://github.com/chapmanb/bcbio-nextgen">bcbio-nextgen</a> variant calling framework, specifically evaluating <a href="https://bcbio.wordpress.com/2013/05/06/framework-for-evaluating-variant-detection-methods-comparison-of-aligners-and-callers/">aligners and variant calling methods</a> and <a href="https://bcbio.wordpress.com/2013/10/21/updated-comparison-of-variant-detection-methods-ensemble-freebayes-and-minimal-bam-preparation-pipelines/">assessing the impact of BAM post-alignment preparation methods</a>. We're continually looking to improve both the pipeline and validation methods and two recent papers helped advance best-practices for evaluating and filtering variant calls: </p>
<ul class="org-ul">
<li><a href="http://research.mssm.edu/linderman/index.html">Michael Linderman and colleagues</a> describe approaches for <a href="http://www.biomedcentral.com/1755-8794/7/20/abstract">validating clinical exome and whole genome sequencing results</a>. One key result I took from the paper was the difference in assessment between exome and whole genome callsets. Coverage differences due to capture characterize discordant exome variants, while complex genome regions drive whole genome discordants. Reading this paper pushed us to evaluate whole genome population based variant calling, which is now feasible due to improvements in bcbio-nextgen scalability. </li>
<li><a href="https://twitter.com/lh3lh3">Heng Li</a> identified <a href="http://arxiv.org/abs/1404.0929">variant calling artifacts and proposed filtering approaches</a> to remove them, as well as characterizing caller error rates. We'll investigate two of the filters he proposed: removing variants in low complexity regions, and filtering high depth variants. </li>
</ul>
<p> We use the <a href="http://ccr.coriell.org/Sections/Search/Sample_Detail.aspx?Ref=GM12878">NA12878/NA12891/NA12892 trio</a> from the <a href="http://blog.goldenhelix.com/wp-content/uploads/2013/03/Utah-Pedigree-1463-with-NA12878.png">CEPH 1463 Pedigree</a> as an input dataset, consisting of 50x whole genome reads from <a href="http://www.illumina.com/platinumgenomes/">Illumina's platinum genomes</a>. This enables both whole genome comparisons, as well as pooled family calling that replicates best-practice for calling within populations. We aligned reads using <a href="http://bio-bwa.sourceforge.net/">bwa-mem</a> and performed streaming de-duplication detection with <a href="https://github.com/GregoryFaust/samblaster">samblaster</a>. Combined with no recalibration or realignment based on <a href="https://bcbio.wordpress.com/2013/10/21/updated-comparison-of-variant-detection-methods-ensemble-freebayes-and-minimal-bam-preparation-pipelines/">our previous assessment</a>, this enabled fully streamed preparation of BAM files from input fastq reads. We called variants using two realigning callers: <a href="https://github.com/ekg/freebayes">FreeBayes (v0.9.14-7)</a> and <a href="http://www.broadinstitute.org/gatk/gatkdocs/org_broadinstitute_sting_gatk_walkers_haplotypecaller_HaplotypeCaller.html">GATK HaplotypeCaller (3.1-1-g07a4bf8)</a> and evaluated calls using the <a href="http://www.nature.com/nbt/journal/v32/n3/full/nbt.2835.html">Genome in a Bottle reference callset for NA12878 (v0.2-NIST-RTG)</a>. The bcbio-nextgen documentation has <a href="https://bcbio-nextgen.readthedocs.org/en/latest/contents/testing.html#whole-genome-trio-50x">full instructions for reproducing the analysis</a>. </p>
<p> This work provides three practical improvements for variant calling and validation: </p>
<ul class="org-ul">
<li>Low complexity regions contribute 45% of the indels in whole genome evaluations, and are highly variable between callers. This replicates Heng's results and Michael's assessment of common errors in whole genome samples, and indicates we need to specifically identify and assess the 2% of the genome labeled as low complexity. Practically, we'll exclude them from further evaluations to avoid non-representative bias, and suggest removing or flagging them when producing whole genome variant calls. </li>
<li>We add a filter for removing false positives from FreeBayes calls in high depth, low quality regions. This removes variants in high depth regions that are likely due to copy number or other larger structural events, and replicates Heng's filtering results. </li>
<li>We improved settings for <a href="http://gatkforums.broadinstitute.org/discussion/39/variant-quality-score-recalibration-vqsr">GATK variant quality recalibration (VQSR)</a>. The default VQSR settings are conservative for SNPs and need adjustment to be compatible with the sensitivity available through FreeBayes or GATK using hard filters. </li>
</ul></div>
</p></div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">Low complexity regions</h2>
<div class="outline-text-2" id="text-2">
<p> Low complexity regions (LCRs) consist of locally repetitive sections of the genome. Heng's paper identified these using <a href="http://compbio.dfci.harvard.edu/tgi/software/">mdust</a> and provides a <a href="https://github.com/lh3/varcmp/raw/master/scripts/LCR-hs37d5.bed.gz">BED file of LCRs</a> covering 2% of the genome. Repeats in these regions can lead to artifacts in sequencing and variant calling. Heng's paper provides examples of areas where a full de-novo assembly correctly resolves the underlying structure, while local reassembly variant callers do not. </p>
<p> To assess the impact of low complexity regions on variant calling, we compared calls from FreeBayes and GATK HaplotypeCaller to the Genome in a Bottle reference callset with and without low complexity regions included. The graph below shows concordant non-reference variant calls alongside discordant calls in three categories: missing discordants are potential false negatives, extras are potential false positives, and shared are variants that overlap between the evaluation and reference callsets but differ due to zygosity (heterozygote versus homozygote) or indel representation. </p>
<p>  <a href="http://i.imgur.com/D2z9Kyp.png">   <img src="http://i.imgur.com/D2z9Kyp.png" width="700" alt="Low complexity regions for GATK and FreeBayes validation" /> </a>
<ul class="org-ul">
<li>For SNPs, removing low complexity regions removes approximately ~2% of the total calls for both FreeBayes and GATK. This corresponds to the 2% of the genome subtracted by removing LCRs. </li>
<li>For indels, removing LCRs removes 45% of the calls due to the over-representation of indels in repeat regions. Additionally, this results in approximately equal GATK and FreeBayes concordant indels after LCR removal. Since the Genome in a Bottle reference callset uses GATK HaplotypeCaller to resolve discrepant calls, this change in concordance is likely due to bias towards GATK's approaches for indel resolution in complex regions. </li>
<li>The default GATK VQSR calls for SNPs are not as sensitive, relative to FreeBayes calls. I'll describe additional work to improve this below. </li>
</ul>
<p> Practically, we'll now exclude low complexity regions in variant comparisons to avoid potential bias and more accurately represent calls in the remaining non-LCR genome. We'll additionally flag low complexity indels in non-evaluation callsets as likely to require additional followup. Longer term, we need to incorporate callers specifically designed for repeats like <a href="http://lobstr.teamerlich.org/index.html">lobSTR</a> to more accurately characterize these regions. </p>
</p></div>
</p></div>
<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">High depth, low quality, filter for FreeBayes</h2>
<div class="outline-text-2" id="text-3">
<p> The second filter proposed in Heng's paper was removal of high depth variants. This was a useful change in mindset for me as I've primarily thought about removing low quality, low depth variants. However, high depth regions can indicate potential copy number variations or hidden duplicates which result in spurious calls. </p>
<p> Comparing true and false positive FreeBayes calls with a pooled multi-sample call quality of less than 500 identifies a large grouping of false positive heterozygous variants at a combined depth, across the trio, of 200: </p>
<p>  <a href="http://i.imgur.com/S9lObRf.png">   <img src="http://i.imgur.com/S9lObRf.png" width="700" alt="Heterozygotes by depth and quality: true versus false positive" /> </a>
<p> The cutoff proposed by Heng was to calculate the average depth of called variants and set the cutoff as the average depth plus a multiplier of 3 or 4 times the square root of average depth. This dataset was an average depth of 169 for the trio, corresponding to a cutoff of 208 if we use the 3 multiplier, which compares nicely with a manual cutoff you'd set looking at the above graphs. Applying a cutoff of QUAL &lt; 500 and DP &gt; 208 produces a reduction in false positives with little impact on sensitivity: </p>
<p>  <a href="http://i.imgur.com/zOcrnKS.png">   <img src="http://i.imgur.com/zOcrnKS.png" width="700" alt="Improvement in filtering false positives with high depth filter" /> </a>
<p> A nice bonus of this filter is that it makes intuitive sense: variants with high depth and low quality indicate there is something problematic, and depth manages to partially compensate for the underlying issue. Inspired by <a href="https://www.broadinstitute.org/gatk/gatkdocs/org_broadinstitute_sting_gatk_walkers_annotator_QualByDepth.html">GATK's QualByDepth annotation</a> and default filter of QD &lt; 2.0, we incorporated a generalized version of this into <a href="https://github.com/chapmanb/bcbio-nextgen/blob/master/bcbio/variation/vfilter.py#L75">bcbio-nextgen's FreeBayes filter</a>: QUAL &lt; (depth-cutoff * 2.0) and DP &gt; depth-cutoff. </p>
</p></div>
</p></div>
<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">GATK variant quality score recalibration (VQSR)</h2>
<div class="outline-text-2" id="text-4">
<p> The other area where we needed to improve was using GATK Variant Quality Score Recalibration. The default parameters provide a set of calls that are overly conservative relative to the FreeBayes calls. VQSR provides the ability to tune the filtering so we experimented with multiple configurations to achieve approximately equal sensitivity relative to FreeBayes for both SNPs and Indels. The comparisons use the Genome in a Bottle reference callset for evaluation, and include VQSR default settings, multiple tranche levels and GATK's suggested hard filters: </p>
<p>  <a href="http://i.imgur.com/c4yWTMv.png">   <img src="http://i.imgur.com/c4yWTMv.png" width="700" alt="VQSR tuning: SNPs" /> </a>  <a href="http://i.imgur.com/3yZnkA6.png">   <img src="http://i.imgur.com/3yZnkA6.png" width="700" alt="VQSR tuning: indels" /> </a>
<p> While the sensitivity/specificity tradeoff depends on the research question, in trying to set a generally useful default we'd like to be less conservative than the GATK VQSR default. We learned these tips and tricks for tuning VQSR filtering: </p>
<ul class="org-ul">
<li>The default setting for VQSR is not a tranche level (like 99.0), but rather a LOD score of 0. In this experiment, that corresponded to a tranche of ~99.0 for SNPs and ~98.0 for indels. The best-practice example documentation uses command line parameter that specify a consistent tranche of 99.0 for both SNPs and indels, so depending on which you follow as a default you'll get different sensitivities. </li>
<li>To increase sensitivity, increase the tranche level. My expectations were that decreasing the tranche level would include more variants, but that actually applies additional filters. My suggestion for understanding tranche levels is that they specify the percentage of variants you want to capture; a tranche of 99.9% captures 99.9% of the true cases in the training set, while 99.0% captures less. </li>
<li>We found tranche settings of 99.97% for SNPs and 98.0% for indels correspond to roughly the sensitivity/specificity that you achieve with FreeBayes. These are the new default settings in bcbio-nextgen. </li>
<li>Using <a href="https://github.com/chapmanb/bcbio-nextgen/blob/master/bcbio/variation/vfilter.py#L125">hard filtering of variants based on GATK recommendations</a> performs well and is also a good default choice. For SNPs, the hard filter defaults are less conservative and more in line with FreeBayes results than VQSR defaults. VQSR has improved specificity at the same sensitivity and has the advantage of being configurable, but will require an extra tuning step. </li>
</ul>
<p> Overall VQSR provides good filtering and the ability to tune sensitivity but requires validation work to select tranche cutoffs that are as sensitive as hard filter defaults, since default values tend to be overly conservative for SNP calling. In the absence of the ability or desire to tune VQSR tranche levels, the GATK hard filters provide a nice default without much of a loss in precision. </p>
</p></div>
</p></div>
<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">Data availability and future work</h2>
<div class="outline-text-2" id="text-5">
<p> Thanks to continued community work on improving variant calling evaluations, this post demonstrates practical improvements in bcbio-nextgen variant calling. We welcome interested contributors to re-run and expand on the analysis, with full instructions in the <a href="https://bcbio-nextgen.readthedocs.org/en/latest/contents/testing.html#whole-genome-trio-50x">bcbio-nextgen example pipeline documentation</a>. Some of the output files from the analysis may also be useful: </p>
<ul class="org-ul">
<li>VCF files for FreeBayes <a href="https://s3.amazonaws.com/bcbio_nextgen/comparison3/freebayes-tp-het.vcf.gz">true positive</a> and <a href="https://s3.amazonaws.com/bcbio_nextgen/comparison3/freebayes-fp-het.vcf.gz">false positive</a> heterozygote calls, used here to improve filtering via assessment of high depth regions. Heterozygotes make up the majority of false positive calls so take the most work to correctly filter and detect. </li>
<li><a href="https://s3.amazonaws.com/bcbio_nextgen/comparison3/giab-comparision-shared-gatk-fb-extras.vcf.gz">Shared false positives from FreeBayes and GATK HaplotypeCaller</a>. These are potential missing variants in the Genome in a Bottle reference. Alternatively, they may represent persistent errors found in multiple callers. </li>
</ul>
<p> We plan to continue to explore variant calling improvements in bcbio-nextgen. Our next steps are to use the trio population framework to compared pooled population calling versus <a href="http://gatkforums.broadinstitute.org/discussion/3896/the-gatk-reference-model-pipeline-for-incremental-joint-discovery-in-full-detail">the incremental joint discovery approach introduced in GATK 3</a>. We'd also like to compare with single sample calling followed by <a href="https://github.com/chapmanb/bcbio.variation.recall">subsequent squaring off/backfilling</a> to assess the value of concurrent population calling. We welcome suggestions and thoughts on this work and future directions. </p>
</p></div>
</p></div>
