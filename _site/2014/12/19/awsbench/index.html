<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Benchmarking variation and RNA-seq analyses on Amazon Web Services with Docker &#8211; Blue Collar Bioinformatics</title>

<meta name="keywords" content="infrastructure, benchmarking, small-variants, rna-seq">

  

<!-- Twitter Cards -->
<meta name="twitter:title" content="Benchmarking variation and RNA-seq analyses on Amazon Web Services with Docker">

<meta name="twitter:site" content="@chapmanb">
<meta name="twitter:creator" content="@chapmanb">

<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://localhost:4000/images/">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Benchmarking variation and RNA-seq analyses on Amazon Web Services with Docker">

<meta property="og:url" content="http://localhost:4000/2014/12/19/awsbench/">
<meta property="og:site_name" content="Blue Collar Bioinformatics">





<link rel="canonical" href="http://localhost:4000/2014/12/19/awsbench/">
<link href="http://feeds2.feedburner.com/bcbio" type="application/atom+xml" rel="alternate" title="Blue Collar Bioinformatics Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<script src="https://use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
  <script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>


<!-- MathJax -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body id="post">

<div class="navigation-wrapper">
	<nav role="navigation" id="site-nav" class="animated drop">
	    <ul>
      
		    
		        
		    
		    <li><a href="http://localhost:4000/" >About</a></li>
		  
		    
		        
		    
		    <li><a href="http://localhost:4000/articles/" >Recent</a></li>
		  
		    
		        
		    
		    <li><a href="http://localhost:4000/tags/" >Topics</a></li>
		  
		    
		        
		    
		    <li><a href="http://localhost:4000/search/" >Search</a></li>
		  
	    </ul>
	</nav>
</div><!-- /.navigation-wrapper -->

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->

<header class="masthead">
	<div class="wrap">
      
      <h1 class="site-title animated fadeIn"><a href="http://localhost:4000/">Blue Collar Bioinformatics</a></h1>
		<h2 class="site-description animated fadeIn" itemprop="description">Biological data analysis, validation and visualization</h2>
	</div>
</header><!-- /.masthead -->

<div class="js-menu-screen menu-screen"></div>


<div id="main" role="main">
  <article class="hentry">
    
    <div class="entry-wrapper">
      <header class="entry-header">
        <span class="entry-tags"><a href="http://localhost:4000/tags/#infrastructure" title="Pages tagged infrastructure">infrastructure</a>&nbsp;&bull;&nbsp;<a href="http://localhost:4000/tags/#benchmarking" title="Pages tagged benchmarking">benchmarking</a>&nbsp;&bull;&nbsp;<a href="http://localhost:4000/tags/#small-variants" title="Pages tagged small-variants">small-variants</a>&nbsp;&bull;&nbsp;<a href="http://localhost:4000/tags/#rna-seq" title="Pages tagged rna-seq">rna-seq</a></span>
        
          <h1 class="entry-title">Benchmarking variation and RNA-seq analyses on Amazon Web Services with Docker</h1>
        
      </header>
      <footer class="entry-meta">
        
          
        
          <img src="http://localhost:4000/images/diego-work.jpg" class="bio-photo" alt="Brad Chapman bio photo"></a>
        
        <span class="author vcard">By <span class="fn">Brad Chapman</span></span>
        <span class="entry-date date published"><time datetime="2014-12-19T10:17:00-05:00"><i class="fa fa-calendar-o"></i> December 19, 2014</time></span>
        
        <span class="entry-comments"><i class="fa fa-comment-o"></i> <a href="#disqus_thread">Comment</a></span>
        
        
      </footer>
      <div class="entry-content">
        <div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Overview</h2>
<div class="outline-text-2" id="text-1">
<p> We developed a freely available, easy to run implementation of <a href="http://github.com/chapmanb/bcbio-nextgen">bcbio-nextgen</a> on <a href="http://aws.amazon.com/">Amazon Web Services (AWS)</a> using <a href="https://docker.com/">Docker</a>. bcbio is a community developed tool providing validated and scalable variant calling and RNA-seq analysis. The AWS implementation automates all of the steps of building a cluster, attaching high performance shared filesystems, and running an analysis. This makes bcbio readily available to the research community without the need to install and configure a local installation. </p>
<p> The entire installation bootstraps from standard Linux AMIs, enabling adjustment of the tools, genome data and installation without needing to prepare custom AMIs. The implementation uses <a href="https://github.com/gc3-uzh-ch/elasticluster">Elasticluster</a> to provision and configure the cluster. We automate the process with <a href="http://boto.readthedocs.org/en/latest/">the boto Python interface to AWS</a> and <a href="http://www.ansible.com/home">Ansible scripts</a>. <a href="https://github.com/chapmanb/bcbio-nextgen-vm">bcbio-vm</a> isolates code and tools inside a <a href="https://docker.com/">Docker</a> container allowing runs on any remote machine with a download of the Docker image and access to the shared filesystem. Analyses run directly from S3 buckets, with automatic streaming download of input data and upload of final processed data. </p>
<p> We provide timing benchmarks for running a full variant calling analysis using <a href="http://github.com/chapmanb/bcbio-nextgen">bcbio</a> on AWS. The benchmark dataset was <a href="https://bcbio-nextgen.readthedocs.org/en/latest/contents/testing.html#cancer-tumor-normal">a cancer tumor/normal evaluation</a>, from <a href="https://www.synapse.org/#!Synapse:syn312572">the ICGC-TCGA DREAM challenge</a>, with 100x coverage in exome regions. We compared the results of running this dataset on 2 different networked filesystems: Lustre and NFS. We also show benchmarks for an RNA-seq dataset using inputs from <a href="http://www.nature.com/nbt/journal/v32/n9/full/nbt.2957.html">the Sequencing Quality Control (SEQC) project</a>. </p>
<p> We developed bcbio on AWS and ran these timing benchmarks thanks to work with great partners. A collaboration with <a href="http://www.biogenidec.com/">Biogen</a> and <a href="http://www.massgeneral.org/research/researchlab.aspx?id=1402">Rudy Tanzi's group at MGH</a> funded the development of bcbio on AWS. A second collaboration with <a href="http://www.intel.com/content/www/us/en/healthcare-it/healthcare-overview.html">Intel Health and Life Sciences</a> and <a href="http://www.astrazeneca.com">AstraZenenca</a> funded the somatic variant calling benchmarking work. We're thankful for all the relationships that make this work possible: </p>
<ul class="org-ul">
<li>John Morrissey automated the process of starting a bcbio cluster on AWS and attaching a Lustre filesystem. He also automated the approach to generating graphs of resource usage from collectl stats and provided critical front line testing and improvements to all the components of the bcbio AWS interaction.
</li>
<li>Kristina Kermanshahche and Robert Read at <a href="http://www.intel.com/content/www/us/en/healthcare-it/healthcare-overview.html">Intel</a> provided great support helping us get the <a href="https://wiki.hpdd.intel.com/display/PUB/Intel+Cloud+Edition+for+Lustre*+Software">Lustre ICEL CloudFormation</a> templates running.
</li>
<li>Ronen Artzi, Michael Heimlich, and Justin Johnson at <a href="http://www.astrazeneca.com">AstraZenenca</a> setup Lustre, Gluster and NFS benchmarks using a bcbio <a href="http://star.mit.edu/cluster/index.html">StarCluster</a> instance. This initial validation was essential for convincing us of the value of moving to a shared filesystem on AWS.
</li>
<li>Jason Tetrault, Karl Gutwin and Hank Wu at <a href="http://www.biogenidec.com/">Biogen</a> provided valuable feedback, suggestions and resources for developing bcbio on AWS.
</li>
<li>Glen Otero parsed the collectl data and provided graphs, which gave us a detailed look into the potential causes of bottlenecks we found in the timings.
</li>
<li>James Cuff, Paul Edmon and the team at <a href="https://rc.fas.harvard.edu/">Harvard FAS research computing</a>   built and administered the Regal Lustre setup used for local testing.
</li>
<li>John Kern and other members of the bcbio community tested, debugged and helped identify issues with the implementation. Community feedback and contributions are essential to bcbio development.
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">Architecture</h2>
<div class="outline-text-2" id="text-2">
<p> The implementation provides both a practical way to run large scale variant calling and RNA-seq analysis, as well as a flexible backend architecture suitable for production quality runs. This writeup might feel a bit like a <a href="https://web.archive.org/web/20131122230658/http://rampantgames.com/blog/2004/10/black-triangle.html">black triangle moment</a> since I also wrote about <a href="https://bcb.io/2011/11/29/making-next-generation-sequencing-analysis-pipelines-easier-with-biocloudcentral-and-galaxy-integration/">running bcbio on AWS three years ago</a>. That implementation was a demonstration for small scale usage rather than a production ready system. We now have a setup we can support and run on <a href="https://bcb.io/2013/05/22/scaling-variant-detection-pipelines-for-whole-genome-sequencing-analysis/">large scale projects</a> thanks to numerous changes in the backend architecture: </p>
<ul class="org-ul">
<li>Amazon, and cloud based providers in general, now provide high end filesystems and networking. Our AWS runs are fast because they use SSD backend storage, fast networking connectivity and high end processors that would be difficult to invest in for a local cluster. Renting these is economically feasible now that we have an approach to provision resources, run the analysis, and tear everything down. The dichotomy between local cluster hardware and cloud hardware will continue to expand with upcoming improvements in <a href="http://aws.amazon.com/blogs/aws/new-c4-instances/">compute (Haswell processors)</a> and <a href="http://www.infoq.com/news/2014/11/new-features-ec2-ebs-s3">storage (16Tb EBS SSD volumes</a>).
</li>
<li>Isolating all of the software and code inside <a href="https://docker.com/">Docker</a> containers enables rapid deployment of fixes and improvements. From an open source support perspective, Amazon provides a consistent cluster environment we have full control over, limiting the space of potential system specific issues. From a researcher's perspective, this will allow use of bcbio without needing to spend time installing and testing locally.
</li>
<li>The setup runs from standard Linux base images using <a href="http://www.ansible.com/home">Ansible scripts</a> and <a href="https://github.com/gc3-uzh-ch/elasticluster">Elasticluster</a>. This means we no longer need to build and update AMIs for changes in the architecture or code. This simplifies testing and pushing fixes, letting us spend less time on support and more on development. Since we avoid having a pre-built AMI, the process of building and running bcbio on AWS is fully auditable for both security and scientific accuracy. Finally, it provides a path to support bcbio on container specific management services like <a href="http://aws.amazon.com/ecs/">Amazon's EC2 container service</a>.
</li>
<li>All long term data storage happens in <a href="http://aws.amazon.com/s3/">Amazon's S3 object store</a>, including both analysis specific data as well as general reference genome data. Downloading reference data for an analysis on demand removes the requirement to maintain large shared EBS volumes. On the analysis side, you maintain only the input files and high value output files in S3, removing the intermediates upon completion of the analysis. Removing the need to manage storage of EBS volumes also provides a cost savings (<a href="http://aws.amazon.com/s3/pricing/">$0.03/Gb/month for S3</a> versus <a href="http://aws.amazon.com/ebs/pricing/">$0.10+/Gb/month for EBS</a>) and allows the option of archiving in <a href="https://aws.amazon.com/glacier/">Glacier</a> for long term storage.
</li>
</ul>
<p> All of these architectural changes provide a setup that is easier to maintain and scale over time. Our goal moving ahead is to provide a researcher friendly interface to setting up and running analyses. We hope to achieve that through the in-development <a href="https://github.com/rabix/common-workflow-language">Common Workflow Language</a> from <a href="http://galaxyproject.org/">Galaxy</a>, <a href="https://arvados.org/">Arvados</a>, <a href="https://www.sbgenomics.com/">Seven Bridges</a>, <a href="http://www.taverna.org.uk/">Taverna</a> and the <a href="http://www.open-bio.org/wiki/Main_Page">open bioinformatics community</a>. </p>
</div>
</div>
<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">Variant calling &#x2013; benchmarking AWS versus local</h2>
<div class="outline-text-2" id="text-3">
<p> We benchmarked somatic variant calling in two environments: on the elasticluster Docker AWS implementation and on local <a href="https://rc.fas.harvard.edu/">Harvard FAS</a> machines. </p>
<ul class="org-ul">
<li>AWS processing was twice as fast as a local run. The gains occur in disk IO intensive steps like alignment post-processing. AWS offers the opportunity to rent SSD backed storage and obtain a 10GigE connected cluster without contention for network resources. Our local test machines have an in-production Lustre filesystem attached to a large highly utilized cluster provided by <a href="https://rc.fas.harvard.edu/">Harvard FAS research computing</a>.
</li>
<li>At this scale Lustre and NFS have similar throughput, with Lustre outperforming NFS during IO intensive steps like alignment, post-processing and large BAM file merging. From <a href="https://bcb.io/2013/05/22/scaling-variant-detection-pipelines-for-whole-genome-sequencing-analysis/">previous benchmarking work</a> we'll need to process additional samples in parallel to fully stress the shared filesystem and differentiate Lustre versus NFS performance. However, the resource plots at this scale show potential future bottlenecks during alignment, post-processing and other IO intensive steps. Generally, having Lustre scaled across 4 <a href="http://en.wikipedia.org/wiki/Logical_unit_number">LUNs</a> per object storage server (OSS) enables better distribution of disk and network resources.
</li>
</ul>
<p> AWS runs use two c3.8xlarge instances clustered in a single <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html">placement group</a>, providing 32 cores and 60Gb of memory per machine. Our local run was comparable with two compute machines, each with 32 cores and 128Gb of memory, connected to a Lustre filesystem. The benchmark is <a href="https://bcbio-nextgen.readthedocs.org/en/latest/contents/testing.html#cancer-tumor-normal">a cancer tumor/normal evaluation</a> consisting of alignment, recalibration, realignment and variant detection with four different callers. The input is a tumor/normal pair from the <a href="https://www.synapse.org/#!Synapse:syn312572">the ICGC-TCGA DREAM challenge</a> with 100x coverage in exome regions. Here are the times, in hours, for each benchmark: </p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups">
<colgroup>
<col class="left" />
<col class="right" />
<col class="right" />
<col class="right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="left">&#xa0;</th>
<th scope="col" class="right">AWS (Lustre)</th>
<th scope="col" class="right">AWS (NFS)</th>
<th scope="col" class="right">Local (Lustre)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="left">Total</td>
<td class="right">4:42</td>
<td class="right">5:05</td>
<td class="right">10:30</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="left">genome data preparation</td>
<td class="right">0:04</td>
<td class="right">0:10</td>
<td class="right">&#xa0;</td>
</tr>
<tr>
<td class="left">alignment preparation</td>
<td class="right">0:12</td>
<td class="right">0:15</td>
<td class="right">&#xa0;</td>
</tr>
<tr>
<td class="left">alignment</td>
<td class="right">0:29</td>
<td class="right">0:52</td>
<td class="right">0:53</td>
</tr>
<tr>
<td class="left">callable regions</td>
<td class="right">0:44</td>
<td class="right">0:44</td>
<td class="right">1:25</td>
</tr>
<tr>
<td class="left">alignment post-processing</td>
<td class="right">0:13</td>
<td class="right">0:21</td>
<td class="right">4:36</td>
</tr>
<tr>
<td class="left">variant calling</td>
<td class="right">2:35</td>
<td class="right">2:05</td>
<td class="right">2:36</td>
</tr>
<tr>
<td class="left">variant post-processing</td>
<td class="right">0:05</td>
<td class="right">0:03</td>
<td class="right">0:22</td>
</tr>
<tr>
<td class="left">prepped BAM merging</td>
<td class="right">0:03</td>
<td class="right">0:18</td>
<td class="right">0:06</td>
</tr>
<tr>
<td class="left">validation</td>
<td class="right">0:05</td>
<td class="right">0:05</td>
<td class="right">0:09</td>
</tr>
<tr>
<td class="left">population database</td>
<td class="right">0:06</td>
<td class="right">0:07</td>
<td class="right">0:09</td>
</tr>
</tbody>
</table>
<p></p>
<p> To provide more insight into the timing differences between these benchmarks, we automated collection and plotting of resource usage on AWS runs. </p>
</div>
</div>
<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">Variant calling &#x2013; resource usage plots</h2>
<div class="outline-text-2" id="text-4">
<p> bcbio retrieves <a href="http://collectl.sourceforge.net/">collectl</a> usage statistics from the server <a href="https://bcbio-nextgen.readthedocs.org/en/latest/contents/cloud.html#graphing-resource-usage">and prepares graphs</a> of CPU, memory, disk and network usage. These plots allow in-depth insight into limiting factors during individual steps in the workflow. </p>
<p> We'll highlight some interesting comparisons between NFS and Lustre during the variant calling benchmarking. During this benchmark, the two critical resources were CPU usage and disk IO on the shared filesystems.  We also measure memory usage but that was not a limiting factor with these analyses. In addition to the comparisons highlighted below, we have the full set of resource usage graphs available for each run: </p>
<ul class="org-ul">
<li><a href="http://imgur.com/a/AZjuC">Variant calling with NFS on AWS</a>
</li>
<li><a href="http://imgur.com/a/HfrqY">Variant calling with Lustre on AWS</a>
</li>
<li><a href="http://imgur.com/a/LSDFz">RNA-seq on a single machine on AWS</a>
</li>
</ul>
</div>
<div id="outline-container-sec-4-1" class="outline-3">
<h3 id="sec-4-1">CPU</h3>
<div class="outline-text-3" id="text-4-1">
<p> These plots compare CPU usage during processing steps for Lustre and NFS. The largest differences between the two runs are in the alignment, alignment post-processing and variant calling steps: </p>
</div>
<div id="outline-container-sec-4-1-1" class="outline-4">
<h4 id="sec-4-1-1">NFS</h4>
<div class="outline-text-4" id="text-4-1-1">
<a href="http://i.imgur.com/iUpvyHx.png"><br />
  <img src="http://i.imgur.com/iUpvyHx.png" width="700" alt="CPU resource usage for NFS during variant calling" /><br />
</a>
</div>
</div>
<div id="outline-container-sec-4-1-2" class="outline-4">
<h4 id="sec-4-1-2">Lustre</h4>
<div class="outline-text-4" id="text-4-1-2">
<a href="http://i.imgur.com/59W8YvL.png"><br />
  <img src="http://i.imgur.com/59W8YvL.png" width="700" alt="CPU resource usage for Lustre during variant calling" /><br />
</a></p>
<p> For alignment and alignment post-processing the Lustre runs show more stable CPU usage. NFS specifically spends more time in the CPU wait state (red line) during IO intensive steps. On larger scale projects this may become a limiting factor in processing throughput. The variant calling step was slower on Lustre than NFS, with inconsistent CPU usage. We'll have to investigate this slowdown further, since no other metrics point to an obvious bottleneck. </p>
</div>
</div>
</div>
<div id="outline-container-sec-4-2" class="outline-3">
<h3 id="sec-4-2">Shared filesystem network usage and IO</h3>
<div class="outline-text-3" id="text-4-2">
<p> These plots compare network usage during processing for Lustre and NFS. We use this as a consistent proxy for the performance of the shared filesystem and disk IO (the <a href="http://imgur.com/a/AZjuC">NFS plots</a> do have directly measured disk IO for comparison purposes). </p>
</div>
<div id="outline-container-sec-4-2-1" class="outline-4">
<h4 id="sec-4-2-1">NFS</h4>
<div class="outline-text-4" id="text-4-2-1">
<a href="http://i.imgur.com/vvru0sv.png"><br />
  <img src="http://i.imgur.com/vvru0sv.png" width="700" alt="Network resource usage NFS" /><br />
</a>
</div>
</div>
<div id="outline-container-sec-4-2-2" class="outline-4">
<h4 id="sec-4-2-2">Lustre</h4>
<div class="outline-text-4" id="text-4-2-2">
<a href="http://i.imgur.com/onut3GI.png"><br />
  <img src="http://i.imgur.com/onut3GI.png" width="700" alt="Network resource usage Lustre" /><br />
</a></p>
<p> The biggest difference in the IO intensive steps is that Lustre network usage is smoother compared to the spiky NFS input/output, due to spreading out read/writes over multiple disks. Including more processes with additional read/writes will help determine how these differences translate to scaling on larger numbers of simultaneous samples. </p>
</div>
</div>
</div>
</div>
<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">RNA-seq benchmarking</h2>
<div class="outline-text-2" id="text-5">
<p> We also ran an RNA-seq analysis using 4 samples from <a href="http://www.nature.com/nbt/journal/v32/n9/full/nbt.2957.html">the Sequencing Quality Control (SEQC) project</a>. Each sample has 15 million 100bp paired reads. bcbio handled trimming, alignment with <a href="https://github.com/alexdobin/STAR">STAR</a>, and quantitation with <a href="http://www.bioconductor.org/packages/release/bioc/html/DEXSeq.html">DEXSeq</a> and <a href="http://cufflinks.cbcb.umd.edu/">Cufflinks</a>. We ran on a single AWS c3.8xlarge machines with 32 cores, 60Gb of memory, and attached SSD storage. </p>
<p> RNA-seq optimization in bcbio is at an earlier stage than variant calling. We've done work to speed up trimming and aligning, but haven't yet optimized the expression and count steps. The analysis runs quickly in 6 1/2 hours, but there is still room for further optimization, and this is a nice example of how we can use benchmarking plots to identify targets for additional work: </p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups">
<colgroup>
<col class="left" />
<col class="right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="left">Total</th>
<th scope="col" class="right">6:25</th>
</tr>
</thead>
<tbody>
<tr>
<td class="left">genome data preparation</td>
<td class="right">0:32</td>
</tr>
<tr>
<td class="left">adapter trimming</td>
<td class="right">0:32</td>
</tr>
<tr>
<td class="left">alignment</td>
<td class="right">0:24</td>
</tr>
<tr>
<td class="left">estimate expression</td>
<td class="right">3:41</td>
</tr>
<tr>
<td class="left">quality control</td>
<td class="right">1:16</td>
</tr>
</tbody>
</table>
<p></p>
<p> The <a href="http://imgur.com/a/LSDFz">RNA-seq collectl plots</a> show the cause of the slower steps during expression estimation and quality control. Here is CPU usage over the run: </p>
<p><a href="http://i.imgur.com/D43c94L.png"><br />
  <img src="http://i.imgur.com/D43c94L.png" width="700" alt="RNA-seq CPU usage" /><br />
</a></p>
<p> The low CPU usage during the first 2 hours of expression estimation corresponds to DEXSeq running serially over the 4 samples. In contrast with Cufflinks, which parallelizes over all 32 cores, DEXSeq runs in a single core. We could run these steps in parallel by using multiprocessing to launch the jobs, split by sample. Similarly, the QC steps could benefit from parallel processing. Alternatively, we're looking at validating other approaches for doing quantification like <a href="http://bio.math.berkeley.edu/eXpress/">eXpress</a>. These are the type of benchmarking and validation steps that are continually ongoing in the development of bcbio pipelines. </p>
</div>
</div>
<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6">Reproducing the analysis</h2>
<div class="outline-text-2" id="text-6">
<p> The process to launch the cluster and an NFS or optional Lustre shared filesystem is <a href="https://bcbio-nextgen.readthedocs.org/en/latest/contents/cloud.html">fully automated and documented</a>. It sets up permissions, VPCs, clusters and shared filesystems from a basic AWS account, so requires minimal manual work. <code>bcbio_vm.py</code> has commands to: </p>
<ul class="org-ul">
<li>Add an IAM user, a VPC and create the Elasticluster config.
</li>
<li>Launch a cluster and bootstrap with the latest bcbio code and data.
</li>
<li>Create and mount a Lustre filesystem attached to the cluster.
</li>
<li>Terminate the cluster and Lustre stack upon completion.
</li>
</ul>
<p> The processing handles download of input data from S3 and upload back to S3 on finalization. We store data encrypted on S3 and manage access using <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html">IAM instance profiles</a>. The examples below show how to run both a somatic variant calling evaluation and an RNA-seq evaluation. </p>
</div>
<div id="outline-container-sec-6-1" class="outline-3">
<h3 id="sec-6-1">Running the somatic variant calling evaluation</h3>
<div class="outline-text-3" id="text-6-1">
<p> This analysis performs evaluation of variant calling using <a href="https://bcbio-nextgen.readthedocs.org/en/latest/contents/testing.html#cancer-tumor-normal">tumor/normal somatic sample from the DREAM challenge</a>. To run, prepare an S3 bucket to run the analysis from. Copy the <a href="https://s3.amazonaws.com/bcbio-syn3-eval/cancer-dream-syn3-aws.yaml">configuration file</a> to your own personal bucket and add a <a href="https://www.broadinstitute.org/gatk/">GATK</a> jar. You can use the AWS console or any available S3 client to do this. For example, using the <a href="https://aws.amazon.com/cli/">AWS command line client</a>: </p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">aws s3 mb s3://YOURBUCKET-syn3-eval
aws s3 cp s3://bcbio-syn3-eval/cancer-dream-syn3-aws.yaml s3://YOURBUCKET-syn3-eval
aws s3 cp GenomeAnalysisTK.jar s3://YOURBUCKET-syn3-eval/jars/</code></pre></div>

<p> Now ssh to the cluster head node, create the work directory and use bcbio_vm to create a batch script that we submit to SLURM. This example uses an attached Lustre filesystem: </p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">bcbio_vm.py elasticluster ssh bcbio
sudo mkdir -p /scratch/cancer-dream-syn3-exome
sudo chown ubuntu !<span class="err">$</span>
<span class="nb">cd</span> !<span class="nv">$ </span><span class="o">&amp;&amp;</span> mkdir work <span class="o">&amp;&amp;</span> <span class="nb">cd </span>work
bcbio_vm.py ipythonprep s3://YOURBUCKET-syn3-eval/cancer-dream-syn3-aws.yaml <span class="se">\</span>
                        slurm cloud -n 60
sbatch bcbio_submit.sh</code></pre></div>

<p> This runs alignment and variant calling with multiple callers (MuTect, FreeBayes, VarDict and VarScan), validates against the <a href="https://www.synapse.org/#!Synapse:syn312572">DREAM validation dataset truth calls</a> and uploads the results back to S3 in YOURBUCKET-syn3-eval/final. </p>
</div>
</div>
<div id="outline-container-sec-6-2" class="outline-3">
<h3 id="sec-6-2">Running the RNA-seq evaluation</h3>
<div class="outline-text-3" id="text-6-2">
<p> This example runs an RNA-seq analysis using inputs from <a href="http://www.nature.com/nbt/journal/v32/n9/full/nbt.2957.html">the Sequencing Quality Control (SEQC) project</a>. Full details on the analysis are available in the <a href="https://bcbio-nextgen.readthedocs.org/en/latest/contents/testing.html#rnaseq-example">bcbio example run documentation</a>. To setup the run, we copy the input configuration from a publicly available S3 bucket into your own personal bucket: </p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">aws s3 mb s3://YOURBUCKET-eval-rna-seqc/
aws s3 cp s3://bcbio-eval-rna-seqc/eval-rna-seqc.yaml s3://YOURBUCKET-eval-rnaseqc/</code></pre></div>

<p> Now ssh to the cluster head node, create the work directory and use bcbio_vm to run on 32 cores using the attached EBS SSD filesystem: </p>

<div class="highlight"><pre><code class="language-bash" data-lang="bash">bcbio_vm.py elasticluster ssh bcbio
mkdir -p ~/run/eval-rna-seqc/work
<span class="nb">cd</span> ~/run/eval-rna-seqc/work
bcbio_vm.py run s3://YOURBUCKET-eval-rna-seqc/eval-rna-seqc.yaml -n 32</code></pre></div>


<p> This will process three replicates from two different SEQC panels, performing adapter trimming, alignment with <a href="https://github.com/alexdobin/STAR">STAR</a> and produce counts, <a href="http://cufflinks.cbcb.umd.edu/">Cufflinks quantitation</a> and quality control metrics. The results upload back into your initial S3 bucket as YOURBUCKET-eval-rna-seqc/final, and you can shut down the cluster used for processing. </p>
</div>
</div>
</div>
<div id="outline-container-sec-7" class="outline-2">
<h2 id="sec-7">Costs per hour</h2>
<div class="outline-text-2" id="text-7">
<p> These are the instance costs, per hour, for running a 2 node 64 core cluster and associated Lustre filesystem on AWS. For NFS runs, the compute costs are identical but there will not be any additional instances for the shared filesystem. Other run costs will include EBS volumes, but these are small ($0.13/Gb/month) compared to the instance costs over these time periods. We use S3 for long term storage rather than the Lustre or NFS filesystems. </p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups">
<colgroup>
<col class="left" />
<col class="left" />
<col class="right" />
<col class="left" />
<col class="left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="left">&#xa0;</th>
<th scope="col" class="left">AWS type</th>
<th scope="col" class="right">n</th>
<th scope="col" class="left">each</th>
<th scope="col" class="left">total</th>
</tr>
</thead>
<tbody>
<tr>
<td class="left">compute entry node</td>
<td class="left">c3.large</td>
<td class="right">1</td>
<td class="left">$0.11</td>
<td class="left">&#xa0;</td>
</tr>
<tr>
<td class="left">compute worker nodes</td>
<td class="left">c3.8xlarge</td>
<td class="right">2</td>
<td class="left">$1.68</td>
<td class="left">&#xa0;</td>
</tr>
<tr>
<td class="left">&#xa0;</td>
<td class="left">&#xa0;</td>
<td class="right">&#xa0;</td>
<td class="left">&#xa0;</td>
<td class="left">$3.47/hr</td>
</tr>
<tr>
<td class="left">ost (object data store)</td>
<td class="left">c3.2xlarge</td>
<td class="right">4</td>
<td class="left">$0.42</td>
<td class="left">&#xa0;</td>
</tr>
<tr>
<td class="left">mdt (metadata target)</td>
<td class="left">c3.4xlarge</td>
<td class="right">1</td>
<td class="left">$0.84</td>
<td class="left">&#xa0;</td>
</tr>
<tr>
<td class="left">mgt (management target)</td>
<td class="left">c3.xlarge</td>
<td class="right">1</td>
<td class="left">$0.21</td>
<td class="left">&#xa0;</td>
</tr>
<tr>
<td class="left">NATDevice</td>
<td class="left">m3.medium</td>
<td class="right">1</td>
<td class="left">$0.07</td>
<td class="left">&#xa0;</td>
</tr>
<tr>
<td class="left">Lustre licensing</td>
<td class="left">&#xa0;</td>
<td class="right">1</td>
<td class="left">$0.48</td>
<td class="left">&#xa0;</td>
</tr>
<tr>
<td class="left">&#xa0;</td>
<td class="left">&#xa0;</td>
<td class="right">&#xa0;</td>
<td class="left">&#xa0;</td>
<td class="left">$3.28/hr</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="left">&#xa0;</td>
<td class="left">&#xa0;</td>
<td class="right">&#xa0;</td>
<td class="left">&#xa0;</td>
<td class="left">$6.75/hr</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="outline-container-sec-8" class="outline-2">
<h2 id="sec-8">Work to do</h2>
<div class="outline-text-2" id="text-8">
<p> The bcbio AWS implementation is <a href="https://bcbio-nextgen.readthedocs.org/en/latest/contents/cloud.html">freely available and documented</a> and we'll continue to develop and support it. Some of the areas of immediate improvement we hope to tackle in the future include: </p>
<ul class="org-ul">
<li>Supporting encryption at rest on EBS volumes for both NFS and Lustre to meet the <a href="http://d0.awsstatic.com/whitepapers/compliance/AWS_dBGaP_Genomics_on_AWS_Best_Practices.pdf">security requirements for storing genomic data on AWS</a>. We currently encrypt data stored in S3.
</li>
<li>Run directly on container-based parallel frameworks like Amazon's <a href="http://aws.amazon.com/blogs/aws/ec2-container-service-in-action/">EC2 container service</a>, which is also supported by the <a href="https://coreos.com/docs/running-coreos/cloud-providers/ecs/">CoreOS framework</a>.
</li>
<li>Add spot instance support using <a href="http://clusterk.com/">Clusterk</a> or Elasticluster.
</li>
</ul>
<p> We welcome feedback on the implementation, usage and benchmarking results. </p>
</div>
</div>

        
          <div id="disqus_thread"></div><!-- /#disqus_thread -->
          
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'bcbio'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'https://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        
      </div><!-- /.entry-content -->
    </div><!-- /.entry-wrapper -->
    <nav class="pagination" role="navigation">
      
        <a href="http://localhost:4000/2014/10/07/joint-calling/" class="btn" title="Validating generalized incremental joint variant calling with GATK HaplotypeCaller, FreeBayes, Platypus and samtools">Previous</a>
      
      
        <a href="http://localhost:4000/2015/03/05/cancerval/" class="btn" title="Validating multiple cancer variant callers and prioritization in tumor-only samples">Next</a>
      
    </nav><!-- /.pagination -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    

<div class="social-icons">
	<a href="https://twitter.com/chapmanb" title="Brad Chapman on Twitter" target="_blank"><i class="fa fa-twitter-square fa-2x"></i></a>
	<a href="https://github.com/chapmanb" title="Brad Chapman on Github" target="_blank"><i class="fa fa-github-square fa-2x"></i></a>
	<a href="https://github.com/chapmanb" title="Brad Chapman on Bitbucket" target="_blank"><i class="fa fa-bitbucket-square fa-2x"></i></a>
	
	
	
	
	
	
  
	
	<a href="https://linkedin.com/pub/3/300/8ba" title="Brad Chapman on LinkedIn" target="_blank"><i class="fa fa-linkedin-square fa-2x"></i></a>
  <a href="http://feeds2.feedburner.com/bcbio" title="Atom/RSS feed"><i class="fa fa-rss-square fa-2x"></i></a>
</div><!-- /.social-icons -->

  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = 'http://localhost:4000';
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>




</body>
</html>
